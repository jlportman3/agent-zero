--- a/python/helpers/whisper.py	2025-06-24 01:28:05.769508541 +0000
+++ b/python/helpers/whisper.py	2025-06-24 01:28:15.509515473 +0000
@@ -1,6 +1,7 @@
 import base64
 import warnings
 import whisper
+import torch
 import tempfile
 import asyncio
 from python.helpers import runtime, rfc, settings
@@ -30,7 +31,8 @@
         is_updating_model = True
         if not _model or _model_name != model_name:
                 PrintStyle.standard(f"Loading Whisper model: {model_name}")
-                _model = whisper.load_model(name=model_name) # type: ignore
+                device = "cuda" if torch.cuda.is_available() else "cpu"
+                _model = whisper.load_model(name=model_name, device=device) # type: ignore
                 _model_name = model_name
     finally:
         is_updating_model = False
@@ -56,5 +58,5 @@
         audio_file.write(audio_bytes)
 
     # Transcribe the audio file
-    result = _model.transcribe(audio_file.name, fp16=False) # type: ignore
+    result = _model.transcribe(audio_file.name, fp16=torch.cuda.is_available()) # type: ignore
     return result
